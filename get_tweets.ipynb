{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import constants\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Keys & Create Tweepy Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\nUnauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bearer_token \u001b[39m=\u001b[39m constants\u001b[39m.\u001b[39mTWITTER_BEARER_TOKEN\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m client \u001b[39m=\u001b[39m tweepy\u001b[39m.\u001b[39mClient(bearer_token\u001b[39m=\u001b[39mbearer_token)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m resp \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49msearch_recent_tweets(\u001b[39m'\u001b[39;49m\u001b[39m#elks\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:1266\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[39m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[39m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query\n\u001b[1;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m   1267\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m/2/tweets/search/recent\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m   1268\u001b[0m     endpoint_parameters\u001b[39m=\u001b[39;49m(\n\u001b[0;32m   1269\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mend_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mexpansions\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_results\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmedia.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1270\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnext_token\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mplace.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpoll.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1271\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msince_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msort_order\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstart_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtweet.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1272\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39muntil_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39muser.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1273\u001b[0m     ), data_type\u001b[39m=\u001b[39;49mTweet, user_auth\u001b[39m=\u001b[39;49muser_auth\n\u001b[0;32m   1274\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[39mself\u001b[39m, method, route, params\u001b[39m=\u001b[39m{}, endpoint_parameters\u001b[39m=\u001b[39m(), json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_auth\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(method, route, params\u001b[39m=\u001b[39;49mrequest_params,\n\u001b[0;32m    130\u001b[0m                             json\u001b[39m=\u001b[39;49mjson, user_auth\u001b[39m=\u001b[39;49muser_auth)\n\u001b[0;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_type \u001b[39mis\u001b[39;00m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:98\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m BadRequest(response)\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m Unauthorized(response)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m Forbidden(response)\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized\nUnauthorized"
     ]
    }
   ],
   "source": [
    "\n",
    "bearer_token = constants.TWITTER_BEARER_TOKEN\n",
    "\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#billsmafia OR #gobills OR #bills) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from team_queries import team_queries\n",
    "team_queries[str('bills')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Team Search - No Pagination\n",
    "Can use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\nUnauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     team_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39msearch_recent_tweets(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             team_query, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             max_results\u001b[39m=\u001b[39mmax_results, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             tweet_fields\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mauthor_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcreated_at\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m team_response\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m bills_response \u001b[39m=\u001b[39m build_team_search(team_queries[\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mbills\u001b[39;49m\u001b[39m'\u001b[39;49m)], max_results\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m bills_response\u001b[39m.\u001b[39mdata\n",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 6\u001b[0m in \u001b[0;36mbuild_team_search\u001b[1;34m(team_query, max_results)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_team_search\u001b[39m(team_query, max_results \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     team_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49msearch_recent_tweets(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             team_query, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             max_results\u001b[39m=\u001b[39;49mmax_results, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             tweet_fields\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mauthor_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcreated_at\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m team_response\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:1266\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[39m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[39m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query\n\u001b[1;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m   1267\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m/2/tweets/search/recent\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m   1268\u001b[0m     endpoint_parameters\u001b[39m=\u001b[39;49m(\n\u001b[0;32m   1269\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mend_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mexpansions\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_results\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmedia.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1270\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnext_token\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mplace.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpoll.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1271\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msince_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msort_order\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstart_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtweet.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1272\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39muntil_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39muser.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1273\u001b[0m     ), data_type\u001b[39m=\u001b[39;49mTweet, user_auth\u001b[39m=\u001b[39;49muser_auth\n\u001b[0;32m   1274\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[39mself\u001b[39m, method, route, params\u001b[39m=\u001b[39m{}, endpoint_parameters\u001b[39m=\u001b[39m(), json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_auth\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(method, route, params\u001b[39m=\u001b[39;49mrequest_params,\n\u001b[0;32m    130\u001b[0m                             json\u001b[39m=\u001b[39;49mjson, user_auth\u001b[39m=\u001b[39;49muser_auth)\n\u001b[0;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_type \u001b[39mis\u001b[39;00m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:98\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m BadRequest(response)\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m Unauthorized(response)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m Forbidden(response)\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized\nUnauthorized"
     ]
    }
   ],
   "source": [
    "# build search tweets \n",
    "# will use paginate normally, test case\n",
    "\n",
    "# max_results min = 10\n",
    "def build_team_search(team_query, max_results = 10):\n",
    "    team_response = client.search_recent_tweets(\n",
    "            team_query, \n",
    "            max_results=max_results, \n",
    "            tweet_fields=[\"author_id\", \"created_at\", \"text\"], \n",
    "        )\n",
    "    return team_response\n",
    "\n",
    "# bills_response = build_team_search(team_queries[str('bills')], max_results=10)\n",
    "# bills_response.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get times and games from schedule data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get games from schedule\n",
    "2. For each game\n",
    "    a. get both teams\n",
    "    b. get date & time\n",
    "    c. get week\n",
    "    d. get home and away ? not sure need this\n",
    "3. For each game create database of tweets for each team\n",
    "    a. build query\n",
    "        i. Queries are always the same, can just create a dict of queries\n",
    "    b. get start time (4 days before game?) and end time (1 hr before game)\n",
    "    b. pagination function\n",
    "        ii. start time & end time\n",
    "    b. create database of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Schedule CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_schedule_csv(filepath):\n",
    "    sched_df = pd.read_csv(filepath, infer_datetime_format=True)\n",
    "\n",
    "    # convert all datetime fields to datetime type\n",
    "    sched_df['GameTime'] = pd.to_datetime(sched_df['GameTime'])\n",
    "    sched_df['SearchStartTime'] = pd.to_datetime(sched_df['SearchStartTime'])\n",
    "    sched_df['SearchEndTime'] = pd.to_datetime(sched_df['SearchEndTime'])\n",
    "\n",
    "    # convert datetime to twitter appropriate format for datetime requests\n",
    "    sched_df['GameTime'] = sched_df['GameTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    sched_df['SearchStartTime'] = sched_df['SearchStartTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    sched_df['SearchEndTime'] = sched_df['SearchEndTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    return sched_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>SearchStartTime</th>\n",
       "      <th>SearchEndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>8:15 PM</td>\n",
       "      <td>rams</td>\n",
       "      <td>raiders</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2022-12-09T01:15:00Z</td>\n",
       "      <td>2022-12-05T00:15:00Z</td>\n",
       "      <td>2022-12-09T00:15:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week  Day        Date     Time  home     away  home_score  away_score  \\\n",
       "0    14  Thu  2022-12-08  8:15 PM  rams  raiders          17          16   \n",
       "\n",
       "               GameTime       SearchStartTime         SearchEndTime  \n",
       "0  2022-12-09T01:15:00Z  2022-12-05T00:15:00Z  2022-12-09T00:15:00Z  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagination\n",
    "\n",
    "Requests limited to 100 tweets at a time\n",
    "\n",
    "Must paginate requests using ```tweepy.Paginator```   \n",
    "```limit```: sets how many pages  \n",
    "```max_results```: sets how many results per page (limited to 100)  \n",
    "Total Results = limit * max_results  \n",
    "\n",
    "```start_time```: start of when to retrieve tweets  \n",
    "```end_time```: end of when to retrieve tweets  \n",
    "**Note**: times are in format of ```2022-11-24T15:25:00Z```  \n",
    "This is ZULU time which is **7 hours ahead of MST**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Team Paginator Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check start time within 7 days\n",
    "\n",
    "def check_start_time_not_greater_7_days(start_time):\n",
    "    week_ago = dt.datetime.utcnow() - pd.to_timedelta('7 days')\n",
    "    # print('1 week ago:', week_ago, '\\t Start_time: ', start_time)\n",
    "    check = week_ago < dt.datetime.strptime(start_time, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    # if (check == False):\n",
    "    #     print('Start time too old')\n",
    "    # else:\n",
    "    #     print('Start time allowed')\n",
    "    return check\n",
    "\n",
    "check_start_time_not_greater_7_days('2022-12-05T00:15:00Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_time=2019-01-01T17:00:00Z\n",
    "# end_time=2020-12-12T01:00:00Z\n",
    "#2022-11-23T20:05:00Z\t\n",
    "\n",
    "def paginate_search(team_query, max_results, start_time, end_time, limit=20):\n",
    "    start_valid = check_start_time_not_greater_7_days(start_time)\n",
    "    tweet_fields = [\"author_id\", \"created_at\", \"text\"]\n",
    "    \n",
    "    if (start_valid == True):\n",
    "        paginator = tweepy.Paginator(\n",
    "            client.search_recent_tweets, \n",
    "            query = team_query, \n",
    "            tweet_fields = tweet_fields, \n",
    "            start_time=start_time, \n",
    "            end_time=end_time,\n",
    "            max_results = max_results,\n",
    "            limit = limit\n",
    "        )\n",
    "        return paginator\n",
    "    else:\n",
    "        # run query with start time being one week ago + 1 minute\n",
    "        # otherwise time becomes invalid by time last pages come through, need the buffer\n",
    "        start_time = dt.datetime.utcnow() - pd.to_timedelta('7 days') + pd.to_timedelta('1 minute')\n",
    "        print('Start Time Not Valid', team_query[2:30], '\\n New Sart Time: ', start_time)\n",
    "        paginator = tweepy.Paginator(\n",
    "            client.search_recent_tweets, \n",
    "            query = team_query, \n",
    "            tweet_fields = tweet_fields, \n",
    "            start_time=start_time, \n",
    "            end_time=end_time,\n",
    "            max_results = max_results,\n",
    "            limit = limit\n",
    "        )\n",
    "        return paginator\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Paginator Search from Game Schedule\n",
    "Iterate through each game row  \n",
    "Get all data needed  \n",
    "Call paginae search for both home and away teams  \n",
    "Add to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paginator_dict_key(wk, team):\n",
    "    team_key = 'wk_' + str(wk) + '_' + team\n",
    "    return team_key\n",
    "\n",
    "def create_week_paginations_from_schedule(wk_sched_df, team_queries, max_results = 100, limit = 80):\n",
    "    # create empty paginators dict\n",
    "    paginators = {}\n",
    "\n",
    "    # iterate through each game row\n",
    "    for game_row in wk_sched_df.itertuples():\n",
    "        wk = game_row.Week\n",
    "\n",
    "        # get search start and end times\n",
    "        \n",
    "        start_time = game_row.SearchStartTime\n",
    "        end_time = game_row.SearchEndTime\n",
    "        \n",
    "        #get home and away teams\n",
    "        home_team = game_row.home\n",
    "        away_team = game_row.away\n",
    "\n",
    "        # get team queries\n",
    "        home_team_query = team_queries[str(home_team)]\n",
    "        away_team_query = team_queries[str(away_team)]\n",
    "\n",
    "        # create team paginators for home and away\n",
    "        home_team_paginator = paginate_search(\n",
    "            home_team_query, \n",
    "            max_results, \n",
    "            start_time, \n",
    "            end_time,\n",
    "            limit\n",
    "        )\n",
    "        away_team_paginator = paginate_search(\n",
    "            away_team_query, \n",
    "            max_results, \n",
    "            start_time, \n",
    "            end_time,\n",
    "            limit\n",
    "        )\n",
    "\n",
    "        # create dict key from         \n",
    "        home_key = get_paginator_dict_key(wk, home_team)\n",
    "        away_key = get_paginator_dict_key(wk, away_team)\n",
    "\n",
    "        # add paginators to dict\n",
    "        paginators[home_key] = {\n",
    "            \"paginator\": home_team_paginator,\n",
    "            \"team\": home_team\n",
    "        }\n",
    "        paginators[away_key] = {\n",
    "            \"paginator\": away_team_paginator,\n",
    "            \"team\": away_team\n",
    "        }\n",
    "        \n",
    "    return paginators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV file for team\n",
    "- Tweet Team\n",
    "- Tweet Text\n",
    "- Tweet Author\n",
    "- Tweet Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "\n",
    "def create_tweet_save_path (week, key):\n",
    "    return  f'./team_data/wk_{week}/{key}_tweets.csv'\n",
    "\n",
    "\n",
    "# 'team_data/%s_tweets.csv' % (key)\n",
    "def create_dataset(paginator_dict, key, week_num):\\\n",
    "    # get team and paginator\n",
    "    team = paginator_dict[str(\"team\")]\n",
    "    paginator = paginator_dict[str(\"paginator\")]\n",
    "\n",
    "    # create save path for tweet csv's\n",
    "    file_save_path = create_tweet_save_path(week_num, key)\n",
    "    \n",
    "    with open(file_save_path, 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        \n",
    "        # Write header row (feature column names of your choice)\n",
    "        w.writerow(['team',\n",
    "                     'timestamp', \n",
    "                     'tweet_text', \n",
    "                     'userid' \n",
    "                     ])\n",
    "        # initiate tweet and page counts\n",
    "        tweet_count = 0\n",
    "        page_count = 0\n",
    "        \n",
    "        # iterate through pages of tweets\n",
    "        for page in paginator: \n",
    "            page_count += 1\n",
    "\n",
    "            # if no data found record and skip\n",
    "            if (page.data == None):\n",
    "                print(f'NO DATA FOR {team}')\n",
    "                print(page.meta)\n",
    "            \n",
    "            else:\n",
    "                # For each tweet add to csv file\n",
    "                for tweet in page.data:\n",
    "                    tweet_count += 1\n",
    "                \n",
    "                    w.writerow([team,\n",
    "                                tweet.created_at, \n",
    "                                tweet.text.replace('\\n',' ').encode('utf-8'), \n",
    "                                tweet.author_id, \n",
    "                                ])\n",
    "        # record data\n",
    "        print(f'Team: {team} \\t\\t Page Count: {page_count} \\t Tweet Count: {tweet_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_team_datasets(team_paginators, week_num):\n",
    "    # iterate through team paginator dict\n",
    "    for key, paginator_dict in team_paginators.items():\n",
    "        # print('KEY:%s - PAGINATOR: %s ' %(key, paginator_dict))\n",
    "        # pass each to create_dataset\n",
    "        create_dataset(paginator_dict, key, week_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Code to get all Datasets\n",
    "\n",
    "1. create new filepath following template for new schedule\n",
    "2. import schedule with the filepath and save df\n",
    "3. Select which lines to run the code, might be only have certain games ```sched_14_df[4:9]``` etc.  \n",
    "4. set `week_num = ##`  \n",
    "5. set the dataframe parameter in the ```create_week_paginations_from_schedule```\n",
    "6. Run Code  \n",
    "7. commit to github so that have data if it gets lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'import_schedule_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m filepath_13 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./schedules/schedule_wk_13_cleaned.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filepath_14 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./schedules/schedule_wk_14_cleaned.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sched_14_df \u001b[39m=\u001b[39m import_schedule_csv(filepath_14)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sched_14_df_mon \u001b[39m=\u001b[39m sched_14_df[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m sched_14_df_mon\n",
      "\u001b[1;31mNameError\u001b[0m: name 'import_schedule_csv' is not defined"
     ]
    }
   ],
   "source": [
    "filepath_13 = './schedules/schedule_wk_13_cleaned.csv'\n",
    "filepath_14 = './schedules/schedule_wk_14_cleaned.csv'\n",
    "\n",
    "sched_14_df = import_schedule_csv(filepath_14)\n",
    "sched_14_df_mon = sched_14_df[-1:]\n",
    "sched_14_df_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\nUnauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m week_num \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m14\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m paginators_wk14 \u001b[39m=\u001b[39m create_week_paginations_from_schedule(sched_14_df_mon, team_queries, \u001b[39m100\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m create_all_team_datasets(paginators_wk14, week_num)\n",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 23\u001b[0m in \u001b[0;36mcreate_all_team_datasets\u001b[1;34m(team_paginators, week_num)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_all_team_datasets\u001b[39m(team_paginators, week_num):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# iterate through team paginator dict\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key, paginator_dict \u001b[39min\u001b[39;00m team_paginators\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m# print('KEY:%s - PAGINATOR: %s ' %(key, paginator_dict))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m# pass each to create_dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         create_dataset(paginator_dict, key, week_num)\n",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\NFL_twitter_sentiment_odds\\get_tweets.ipynb Cell 23\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(paginator_dict, key, week_num)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m page_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# iterate through pages of tweets\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m paginator: \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     page_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/NFL_twitter_sentiment_odds/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# if no data found record and skip\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\pagination.py:126\u001b[0m, in \u001b[0;36mPaginationIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mpagination_token\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pagination_token\n\u001b[1;32m--> 126\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(response, Response):\n\u001b[0;32m    129\u001b[0m     meta \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mmeta\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:1266\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[39m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[39m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query\n\u001b[1;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m   1267\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m/2/tweets/search/recent\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m   1268\u001b[0m     endpoint_parameters\u001b[39m=\u001b[39;49m(\n\u001b[0;32m   1269\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mend_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mexpansions\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_results\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmedia.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1270\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnext_token\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mplace.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpoll.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1271\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msince_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msort_order\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstart_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtweet.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1272\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39muntil_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39muser.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1273\u001b[0m     ), data_type\u001b[39m=\u001b[39;49mTweet, user_auth\u001b[39m=\u001b[39;49muser_auth\n\u001b[0;32m   1274\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[39mself\u001b[39m, method, route, params\u001b[39m=\u001b[39m{}, endpoint_parameters\u001b[39m=\u001b[39m(), json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_auth\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(method, route, params\u001b[39m=\u001b[39;49mrequest_params,\n\u001b[0;32m    130\u001b[0m                             json\u001b[39m=\u001b[39;49mjson, user_auth\u001b[39m=\u001b[39;49muser_auth)\n\u001b[0;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_type \u001b[39mis\u001b[39;00m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:98\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m BadRequest(response)\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m Unauthorized(response)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m Forbidden(response)\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized\nUnauthorized"
     ]
    }
   ],
   "source": [
    "week_num = '14'\n",
    "paginators_wk14 = create_week_paginations_from_schedule(sched_14_df_mon, team_queries, 100)\n",
    "create_all_team_datasets(paginators_wk14, week_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to filter out multiteam hashtags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc6efb3340bf4aae142c4471c3414bb5b17e6e80ba42a259676c40f0503db89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
