{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import constants\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Keys & Create Tweepy Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bearer_token = constants.TWITTER_BEARER_TOKEN\n",
    "\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#billsmafia OR #gobills OR #bills) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from team_queries import team_queries\n",
    "team_queries[str('bills')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Team Search - No Pagination\n",
    "Can use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build search tweets \n",
    "# will use paginate normally, test case\n",
    "user_fields = [\"id\"]\n",
    "expansions = [\"author_id\"]\n",
    "\n",
    "# max_results min = 10\n",
    "def build_team_search(team_query, max_results = 10):\n",
    "    team_response = client.search_recent_tweets(\n",
    "            team_query, \n",
    "            max_results=max_results, \n",
    "            tweet_fields=[\"author_id\", \"created_at\", \"text\"], \n",
    "            user_fields=user_fields, \n",
    "            expansions=expansions\n",
    "        )\n",
    "    return team_response\n",
    "\n",
    "# bills_response = build_team_search(team_queries[str('bills')], max_results=10)\n",
    "# bills_response.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get times and games from schedule data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get games from schedule\n",
    "2. For each game\n",
    "    a. get both teams\n",
    "    b. get date & time\n",
    "    c. get week\n",
    "    d. get home and away ? not sure need this\n",
    "3. For each game create database of tweets for each team\n",
    "    a. build query\n",
    "        i. Queries are always the same, can just create a dict of queries\n",
    "    b. get start time (4 days before game?) and end time (1 hr before game)\n",
    "    b. pagination function\n",
    "        ii. start time & end time\n",
    "    b. create database of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Schedule CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_schedule_csv(filepath):\n",
    "    sched_df = pd.read_csv(filepath, infer_datetime_format=True)\n",
    "\n",
    "    # convert all datetime fields to datetime type\n",
    "    sched_df['GameTime'] = pd.to_datetime(sched_df['GameTime'])\n",
    "    sched_df['SearchStartTime'] = pd.to_datetime(sched_df['SearchStartTime'])\n",
    "    sched_df['SearchEndTime'] = pd.to_datetime(sched_df['SearchEndTime'])\n",
    "\n",
    "    # convert datetime to twitter appropriate format for datetime requests\n",
    "    sched_df['GameTime'] = sched_df['GameTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    sched_df['SearchStartTime'] = sched_df['SearchStartTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    sched_df['SearchEndTime'] = sched_df['SearchEndTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    return sched_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>SearchStartTime</th>\n",
       "      <th>SearchEndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>8:15 PM</td>\n",
       "      <td>rams</td>\n",
       "      <td>raiders</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2022-12-09T01:15:00Z</td>\n",
       "      <td>2022-12-05T00:15:00Z</td>\n",
       "      <td>2022-12-09T00:15:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week  Day        Date     Time  home     away  home_score  away_score  \\\n",
       "0    14  Thu  2022-12-08  8:15 PM  rams  raiders          17          16   \n",
       "\n",
       "               GameTime       SearchStartTime         SearchEndTime  \n",
       "0  2022-12-09T01:15:00Z  2022-12-05T00:15:00Z  2022-12-09T00:15:00Z  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagination\n",
    "\n",
    "Requests limited to 100 tweets at a time\n",
    "\n",
    "Must paginate requests using ```tweepy.Paginator```   \n",
    "```limit```: sets how many pages  \n",
    "```max_results```: sets how many results per page (limited to 100)  \n",
    "Total Results = limit * max_results  \n",
    "\n",
    "```start_time```: start of when to retrieve tweets  \n",
    "```end_time```: end of when to retrieve tweets  \n",
    "**Note**: times are in format of ```2022-11-24T15:25:00Z```  \n",
    "This is ZULU time which is **7 hours ahead of MST**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Team Paginator Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check start time within 7 days\n",
    "\n",
    "def check_start_time_not_greater_7_days(start_time):\n",
    "    week_ago = dt.datetime.utcnow() - pd.to_timedelta('7 days')\n",
    "    # print('1 week ago:', week_ago, '\\t Start_time: ', start_time)\n",
    "    check = week_ago < dt.datetime.strptime(start_time, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    # if (check == False):\n",
    "    #     print('Start time too old')\n",
    "    # else:\n",
    "    #     print('Start time allowed')\n",
    "    return check\n",
    "\n",
    "check_start_time_not_greater_7_days('2022-12-05T00:15:00Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_time=2019-01-01T17:00:00Z\n",
    "# end_time=2020-12-12T01:00:00Z\n",
    "#2022-11-23T20:05:00Z\t\n",
    "\n",
    "def paginate_search(team_query, max_results, start_time, end_time, limit=20):\n",
    "    start_valid = check_start_time_not_greater_7_days(start_time)\n",
    "    tweet_fields = [\"author_id\", \"created_at\", \"text\"]\n",
    "    \n",
    "    if (start_valid == True):\n",
    "        paginator = tweepy.Paginator(\n",
    "            client.search_recent_tweets, \n",
    "            query = team_query, \n",
    "            tweet_fields = tweet_fields, \n",
    "            start_time=start_time, \n",
    "            end_time=end_time,\n",
    "            max_results = max_results,\n",
    "            limit = limit\n",
    "        )\n",
    "        return paginator\n",
    "    else:\n",
    "        # run query with start time being one week ago + 1 minute\n",
    "        # otherwise time becomes invalid by time last pages come through, need the buffer\n",
    "        start_time = dt.datetime.utcnow() - pd.to_timedelta('7 days') + pd.to_timedelta('1 minute')\n",
    "        print('Start Time Not Valid', team_query[2:30], '\\n New Sart Time: ', start_time)\n",
    "        paginator = tweepy.Paginator(\n",
    "            client.search_recent_tweets, \n",
    "            query = team_query, \n",
    "            tweet_fields = tweet_fields, \n",
    "            start_time=start_time, \n",
    "            end_time=end_time,\n",
    "            max_results = max_results,\n",
    "            limit = limit\n",
    "        )\n",
    "        return paginator\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Paginator Search from Game Schedule\n",
    "Iterate through each game row  \n",
    "Get all data needed  \n",
    "Call paginae search for both home and away teams  \n",
    "Add to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paginator_dict_key(wk, team):\n",
    "    team_key = 'wk_' + str(wk) + '_' + team\n",
    "    return team_key\n",
    "\n",
    "def create_week_paginations_from_schedule(wk_sched_df, team_queries, max_results = 100, limit = 80):\n",
    "    # create empty paginators dict\n",
    "    paginators = {}\n",
    "\n",
    "    # iterate through each game row\n",
    "    for game_row in wk_sched_df.itertuples():\n",
    "        wk = game_row.Week\n",
    "\n",
    "        # get search start and end times\n",
    "        \n",
    "        start_time = game_row.SearchStartTime\n",
    "        end_time = game_row.SearchEndTime\n",
    "        \n",
    "        #get home and away teams\n",
    "        home_team = game_row.home\n",
    "        away_team = game_row.away\n",
    "\n",
    "        # get team queries\n",
    "        home_team_query = team_queries[str(home_team)]\n",
    "        away_team_query = team_queries[str(away_team)]\n",
    "\n",
    "        # create team paginators for home and away\n",
    "        home_team_paginator = paginate_search(\n",
    "            home_team_query, \n",
    "            max_results, \n",
    "            start_time, \n",
    "            end_time,\n",
    "            limit\n",
    "        )\n",
    "        away_team_paginator = paginate_search(\n",
    "            away_team_query, \n",
    "            max_results, \n",
    "            start_time, \n",
    "            end_time,\n",
    "            limit\n",
    "        )\n",
    "\n",
    "        # create dict key from         \n",
    "        home_key = get_paginator_dict_key(wk, home_team)\n",
    "        away_key = get_paginator_dict_key(wk, away_team)\n",
    "\n",
    "        # add paginators to dict\n",
    "        paginators[home_key] = {\n",
    "            \"paginator\": home_team_paginator,\n",
    "            \"team\": home_team\n",
    "        }\n",
    "        paginators[away_key] = {\n",
    "            \"paginator\": away_team_paginator,\n",
    "            \"team\": away_team\n",
    "        }\n",
    "        \n",
    "    return paginators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV file for team\n",
    "- Tweet Team\n",
    "- Tweet Text\n",
    "- Tweet Author\n",
    "- Tweet Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "\n",
    "def create_tweet_save_path (week, key):\n",
    "    return  f'./team_data/wk_{week}/{key}_tweets.csv'\n",
    "\n",
    "\n",
    "# 'team_data/%s_tweets.csv' % (key)\n",
    "def create_dataset(paginator_dict, key, week_num):\\\n",
    "    # get team and paginator\n",
    "    team = paginator_dict[str(\"team\")]\n",
    "    paginator = paginator_dict[str(\"paginator\")]\n",
    "\n",
    "    # create save path for tweet csv's\n",
    "    file_save_path = create_tweet_save_path(week_num, key)\n",
    "    \n",
    "    with open(file_save_path, 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        \n",
    "        # Write header row (feature column names of your choice)\n",
    "        w.writerow(['team',\n",
    "                     'timestamp', \n",
    "                     'tweet_text', \n",
    "                     'userid' \n",
    "                     ])\n",
    "        # initiate tweet and page counts\n",
    "        tweet_count = 0\n",
    "        page_count = 0\n",
    "        \n",
    "        # iterate through pages of tweets\n",
    "        for page in paginator: \n",
    "            page_count += 1\n",
    "\n",
    "            # if no data found record and skip\n",
    "            if (page.data == None):\n",
    "                print(f'NO DATA FOR {team}')\n",
    "                print(page.meta)\n",
    "            \n",
    "            else:\n",
    "                # For each tweet add to csv file\n",
    "                for tweet in page.data:\n",
    "                    tweet_count += 1\n",
    "                \n",
    "                    w.writerow([team,\n",
    "                                tweet.created_at, \n",
    "                                tweet.text.replace('\\n',' ').encode('utf-8'), \n",
    "                                tweet.author_id, \n",
    "                                ])\n",
    "        # record data\n",
    "        print(f'Team: {team} \\t\\t Page Count: {page_count} \\t Tweet Count: {tweet_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_team_datasets(team_paginators, week_num):\n",
    "    # iterate through team paginator dict\n",
    "    for key, paginator_dict in team_paginators.items():\n",
    "        # print('KEY:%s - PAGINATOR: %s ' %(key, paginator_dict))\n",
    "        # pass each to create_dataset\n",
    "        create_dataset(paginator_dict, key, week_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Code to get all Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>SearchStartTime</th>\n",
       "      <th>SearchEndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>4:25 PM</td>\n",
       "      <td>seahawks</td>\n",
       "      <td>panthers</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>2022-12-11T21:25:00Z</td>\n",
       "      <td>2022-12-07T20:25:00Z</td>\n",
       "      <td>2022-12-11T20:25:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>4:25 PM</td>\n",
       "      <td>49ers</td>\n",
       "      <td>buccaneers</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-11T21:25:00Z</td>\n",
       "      <td>2022-12-07T20:25:00Z</td>\n",
       "      <td>2022-12-11T20:25:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>8:20 PM</td>\n",
       "      <td>chargers</td>\n",
       "      <td>dolphins</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>2022-12-12T01:20:00Z</td>\n",
       "      <td>2022-12-08T00:20:00Z</td>\n",
       "      <td>2022-12-12T00:20:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Week  Day        Date     Time      home        away  home_score  \\\n",
       "9     14  Sun  2022-12-11  4:25 PM  seahawks    panthers          24   \n",
       "10    14  Sun  2022-12-11  4:25 PM     49ers  buccaneers          35   \n",
       "11    14  Sun  2022-12-11  8:20 PM  chargers    dolphins          23   \n",
       "\n",
       "    away_score              GameTime       SearchStartTime  \\\n",
       "9           30  2022-12-11T21:25:00Z  2022-12-07T20:25:00Z   \n",
       "10           7  2022-12-11T21:25:00Z  2022-12-07T20:25:00Z   \n",
       "11          17  2022-12-12T01:20:00Z  2022-12-08T00:20:00Z   \n",
       "\n",
       "           SearchEndTime  \n",
       "9   2022-12-11T20:25:00Z  \n",
       "10  2022-12-11T20:25:00Z  \n",
       "11  2022-12-12T00:20:00Z  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_13 = './schedules/schedule_wk_13_cleaned.csv'\n",
    "filepath_14 = './schedules/schedule_wk_14_cleaned.csv'\n",
    "\n",
    "sched_14_df = import_schedule_csv(filepath_14)\n",
    "sched_14_df_sun_last = sched_14_df[9:]\n",
    "sched_14_df_sun_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team: bills \t\t Page Count: 50 \t Tweet Count: 4995\n",
      "Team: jets \t\t Page Count: 23 \t Tweet Count: 2260\n",
      "Team: bengals \t\t Page Count: 26 \t Tweet Count: 2498\n",
      "Team: browns \t\t Page Count: 34 \t Tweet Count: 3369\n",
      "Team: cowboys \t\t Page Count: 33 \t Tweet Count: 3255\n",
      "Team: texans \t\t Page Count: 11 \t Tweet Count: 1076\n",
      "Team: lions \t\t Page Count: 28 \t Tweet Count: 2734\n",
      "Team: vikings \t\t Page Count: 34 \t Tweet Count: 3313\n",
      "Team: titans \t\t Page Count: 22 \t Tweet Count: 2104\n",
      "Team: jaguars \t\t Page Count: 9 \t Tweet Count: 886\n",
      "Team: giants \t\t Page Count: 28 \t Tweet Count: 2730\n",
      "Team: eagles \t\t Page Count: 43 \t Tweet Count: 4286\n",
      "Team: steelers \t\t Page Count: 35 \t Tweet Count: 3429\n",
      "Team: ravens \t\t Page Count: 9 \t Tweet Count: 841\n",
      "Team: broncos \t\t Page Count: 23 \t Tweet Count: 2291\n",
      "Team: chiefs \t\t Page Count: 21 \t Tweet Count: 2072\n",
      "Team: seahawks \t\t Page Count: 12 \t Tweet Count: 1106\n"
     ]
    },
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\nToo Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\500RP\\get_tweets.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m week_num \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m14\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m paginators_wk14 \u001b[39m=\u001b[39m create_week_paginations_from_schedule(sched_14_df_sun, team_queries, \u001b[39m100\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m create_all_team_datasets(paginators_wk14, week_num)\n",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\500RP\\get_tweets.ipynb Cell 23\u001b[0m in \u001b[0;36mcreate_all_team_datasets\u001b[1;34m(team_paginators, week_num)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_all_team_datasets\u001b[39m(team_paginators, week_num):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# iterate through team paginator dict\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key, paginator_dict \u001b[39min\u001b[39;00m team_paginators\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m# print('KEY:%s - PAGINATOR: %s ' %(key, paginator_dict))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m# pass each to create_dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         create_dataset(paginator_dict, key, week_num)\n",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\500RP\\get_tweets.ipynb Cell 23\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(paginator_dict, key, week_num)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m page_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# iterate through pages of tweets\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m paginator: \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     page_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/500RP/get_tweets.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# if no data found record and skip\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\pagination.py:98\u001b[0m, in \u001b[0;36mPaginationIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mpagination_token\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pagination_token\n\u001b[1;32m---> 98\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_token \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mprevious_token\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_token \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnext_token\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:1248\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query\n\u001b[1;32m-> 1248\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m   1249\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m/2/tweets/search/recent\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m   1250\u001b[0m     endpoint_parameters\u001b[39m=\u001b[39;49m(\n\u001b[0;32m   1251\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mend_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mexpansions\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmax_results\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmedia.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1252\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnext_token\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mplace.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpoll.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1253\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msince_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msort_order\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstart_time\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtweet.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1254\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39muntil_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39muser.fields\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1255\u001b[0m     ), data_type\u001b[39m=\u001b[39;49mTweet, user_auth\u001b[39m=\u001b[39;49muser_auth\n\u001b[0;32m   1256\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:126\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\u001b[39mself\u001b[39m, method, route, params\u001b[39m=\u001b[39m{}, endpoint_parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    123\u001b[0m                   json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, data_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_auth\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    124\u001b[0m     request_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 126\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(method, route, params\u001b[39m=\u001b[39;49mrequest_params,\n\u001b[0;32m    127\u001b[0m                             json\u001b[39m=\u001b[39;49mjson, user_auth\u001b[39m=\u001b[39;49muser_auth)\n\u001b[0;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_type \u001b[39mis\u001b[39;00m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tweepy\\client.py:114\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(method, route, params, json, user_auth)\n\u001b[0;32m    113\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m TooManyRequests(response)\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m500\u001b[39m:\n\u001b[0;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m TwitterServerError(response)\n",
      "\u001b[1;31mTooManyRequests\u001b[0m: 429 Too Many Requests\nToo Many Requests"
     ]
    }
   ],
   "source": [
    "week_num = '14'\n",
    "paginators_wk14 = create_week_paginations_from_schedule(sched_14_df_sun_last, team_queries, 100)\n",
    "create_all_team_datasets(paginators_wk14, week_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to filter out multiteam hashtags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc6efb3340bf4aae142c4471c3414bb5b17e6e80ba42a259676c40f0503db89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
