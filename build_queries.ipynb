{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import constants\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tweepy Client using bearer token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = constants.TWITTER_BEARER_TOKEN\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build query\n",
    "\n",
    "Want to have it exclude if multiple team tags  \n",
    "Can't include them all however as would go over the query character limit of ~512 \n",
    "\n",
    "Would limit the amount of tweets coming in however would also have to then filter again afterwards to remove the hastags that I couldan't include in the query  \n",
    "\n",
    "Approach 1:\n",
    "- build query and include first 50% of negated hashtags \n",
    "- filter tweets after using 2nd half of hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_team_hashtags_to_negate(team_hashtags, hashtag_list):\n",
    "    team_hashtags = [team.lower() for team in team_hashtags]\n",
    "    hashtag_list = [hashtag.lower() for hashtag in hashtag_list]\n",
    "    output = [b for b in hashtag_list if all(a not in b for a in team_hashtags)]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashtags_all import hashtags\n",
    "from hashtags_stripped import ht_flat, ht_half_1, ht_half_2\n",
    "\n",
    "# test_team_list = [\"bears\", \"bengals\", \"saints\"]\n",
    "team_list = hashtags.keys()\n",
    "\n",
    "# build twitter query for a team \n",
    "# take team name in dictionary and hashtag list\n",
    "# Ex \"(#RuleTheJungle OR #Bengals OR #WhoDey) -is:retweet\"\n",
    "# Important to have the parathensis around the main hashtags or else the retweet parameter won't work\n",
    "\n",
    "def build_team_query(team_name, hashtag_doc, hashtags_all):\n",
    "    \n",
    "    # retrieve team hashtags in list\n",
    "    team_hashtags = hashtag_doc[str(team_name)]\n",
    "\n",
    "    #retrieve non-team hashtags in list\n",
    "    negate_team_hashtags = get_non_team_hashtags_to_negate(team_hashtags, hashtags_all)\n",
    "    \n",
    "    # build start of query\n",
    "    query = '(' + team_hashtags[0]\n",
    "    \n",
    "    # if more than one hashtag, combine using OR statements\n",
    "    if (len(team_hashtags) > 1): \n",
    "        for tag in team_hashtags[1:]:\n",
    "            query = query + ' OR ' + tag\n",
    "\n",
    "    # filter out retweets? - not sure if I should do this or not, likely retweet something you also think\n",
    "    query = query + \") -is:retweet lang:en\"\n",
    "    \n",
    "    # filter out other team hashtags\n",
    "    for tag in negate_team_hashtags:\n",
    "        # stop if length of query is above 500\n",
    "        # limit is 512\n",
    "        if len(query) > 495:\n",
    "            break\n",
    "        query = query + \" -\"+ tag\n",
    "    # print(\"Query Length: \", len(query))\n",
    "    return query\n",
    "\n",
    "def get_all_team_queries(team_list, team_hashtags, negate_hashtags):\n",
    "    queries = {}\n",
    "    for team in team_list:\n",
    "        queries[team] = build_team_query(team ,team_hashtags, negate_hashtags)\n",
    "    return queries\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Team Queries\n",
    "*Only pass in half of the hashtags list to limit the length of the query  \n",
    "Will use the other half ```ht_half_2``` to filter out after the fact\n",
    "\n",
    "Will also have to filter out any other hashtags like #nhl or #college etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falcons': '(#DirtyBirds OR #Falcons) -is:retweet lang:en -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'cardinals': '(#BirdCityFootball OR #cardinals OR #AZCardinals) -is:retweet lang:en -#dirtybirds -#falcons -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'ravens': '(#ravens) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'bills': '(#billsmafia OR #gobills OR #bills) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'panthers': '(#keeppounding OR #panthers) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'bears': '(#DaBears OR #BearsNation OR #Bears) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'bengals': '(#RuleTheJungle OR #Bengals OR #WhoDey) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'browns': '(#Browns OR #ClevelandBrowns  OR #DawgPound) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'cowboys': '(#DallasCowboys OR #Cowboys) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'broncos': '(#BroncosCountry OR #LetsRide OR #Broncos) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'lions': '(#OnePride OR #Lions ) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'packers': '(#GoPackGo OR #Packers) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'texans': '(#WeAreTexans OR #Texans) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'colts': '(#ForTheShoe OR #Colts) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'jaguars': '(#DUUUVAL OR #Jags OR #Jaguars) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#chiefskingdom -#chiefs',\n",
       " 'chiefs': '(#ChiefsKingdom OR #Chiefs) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars',\n",
       " 'rams': '(#RamsHouse OR #Rams) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'chargers': '(#BoltUp OR #Chargers) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'dolphins': '(#FinsUp OR #dolphins) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'vikings': '(#SKOL OR #vikings) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'patriots': '(#ForeverNE OR #Patriots) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'saints': '(#Saints) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'giants': '(#TogetherBlue OR #giants) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'jets': '(#TakeFlight OR #Jets) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'raiders': '(#RaiderNation OR #Raiders) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'eagles': '(#FlyEaglesFly OR #Eagles) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'steelers': '(#HereWeGo OR #Steelers) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'seahawks': '(#seahawks) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " '49ers': '(#FTTB OR #49ers) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'buccaneers': '(#GoBucs OR #bucs OR #buccaneers) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'titans': '(#titans) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs',\n",
       " 'commanders': '(#commanders OR httc) -is:retweet lang:en -#dirtybirds -#falcons -#birdcityfootball -#cardinals -#ravensflock -#ravens -#billsmafia -#gobills -#bills -#keeppounding -#panthers -#dabears -#bearsnation -#bears -#rulethejungle -#bengals -#whodey -#browns -#clevelandbrowns  -#dawgpound -#dallascowboys -#cowboys -#broncoscountry -#letsride -#broncos -#onepride -#lions  -#gopackgo -#packers -#wearetexans -#texans -#fortheshoe -#colts -#duuuval -#jags -#jaguars -#chiefskingdom -#chiefs'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_queries = get_all_team_queries(team_list, hashtags, ht_half_1)\n",
    "len(team_queries)\n",
    "\n",
    "team_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Team Search - No Pagination\n",
    "Can use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build search tweets \n",
    "# will use paginate normally, test case\n",
    "user_fields = [\"id\"]\n",
    "expansions = [\"author_id\"]\n",
    "\n",
    "# max_results min = 10\n",
    "def build_team_search(team_query, max_results = 10):\n",
    "    team_response = client.search_recent_tweets(\n",
    "            team_query, \n",
    "            max_results=max_results, \n",
    "            tweet_fields=[\"author_id\", \"created_at\", \"text\"], \n",
    "            user_fields=user_fields, \n",
    "            expansions=expansions\n",
    "        )\n",
    "    return team_response\n",
    "\n",
    "panthers_resp = build_team_search(team_queries[str('panthers')], max_results=10)\n",
    "panthers_resp.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get times and games from schedule data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get games from schedule\n",
    "2. For each game\n",
    "    a. get both teams\n",
    "    b. get date & time\n",
    "    c. get week\n",
    "    d. get home and away ? not sure need this\n",
    "3. For each game create database of tweets for each team\n",
    "    a. build query\n",
    "        i. Queries are always the same, can just create a dict of queries\n",
    "    b. get start time (4 days before game?) and end time (1 hr before game)\n",
    "    b. pagination function\n",
    "        ii. start time & end time\n",
    "    b. create database of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Schedule CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df = pd.read_csv('./2022_schedule_cleaned.csv', infer_datetime_format=True)\n",
    "\n",
    "# add scores for this week, eventually automatic\n",
    "sched_df.at[15, 'home_score'] = 17.0\n",
    "sched_df.at[15, 'away_score'] = 24.0\n",
    "\n",
    "\n",
    "# convert all datetime fields to datetime type\n",
    "sched_df['GameTime'] = pd.to_datetime(sched_df['GameTime'])\n",
    "sched_df['SearchStartTime'] = pd.to_datetime(sched_df['SearchStartTime'])\n",
    "sched_df['SearchEndTime'] = pd.to_datetime(sched_df['SearchEndTime'])\n",
    "\n",
    "# convert datetime to twitter appropriate format for datetime requests\n",
    "sched_df['GameTime'] = sched_df['GameTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "sched_df['SearchStartTime'] = sched_df['SearchStartTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "sched_df['SearchEndTime'] = sched_df['SearchEndTime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>SearchStartTime</th>\n",
       "      <th>SearchEndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>12:30PM</td>\n",
       "      <td>lions</td>\n",
       "      <td>bills</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2022-11-24T17:30:00Z</td>\n",
       "      <td>2022-11-20T16:30:00Z</td>\n",
       "      <td>2022-11-24T16:30:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>4:30PM</td>\n",
       "      <td>cowboys</td>\n",
       "      <td>giants</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2022-11-24T21:30:00Z</td>\n",
       "      <td>2022-11-20T20:30:00Z</td>\n",
       "      <td>2022-11-24T20:30:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>8:20PM</td>\n",
       "      <td>vikings</td>\n",
       "      <td>patriots</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2022-11-25T01:20:00Z</td>\n",
       "      <td>2022-11-21T00:20:00Z</td>\n",
       "      <td>2022-11-25T00:20:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>1:00PM</td>\n",
       "      <td>titans</td>\n",
       "      <td>bengals</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2022-11-27T18:00:00Z</td>\n",
       "      <td>2022-11-23T17:00:00Z</td>\n",
       "      <td>2022-11-27T17:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>1:00PM</td>\n",
       "      <td>browns</td>\n",
       "      <td>buccaneers</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2022-11-27T18:00:00Z</td>\n",
       "      <td>2022-11-23T17:00:00Z</td>\n",
       "      <td>2022-11-27T17:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Week  Day        Date     Time     home        away  home_score  \\\n",
       "0    12  Thu  2022-11-24  12:30PM    lions       bills        25.0   \n",
       "1    12  Thu  2022-11-24   4:30PM  cowboys      giants        28.0   \n",
       "2    12  Thu  2022-11-24   8:20PM  vikings    patriots        33.0   \n",
       "3    12  Sun  2022-11-27   1:00PM   titans     bengals        16.0   \n",
       "4    12  Sun  2022-11-27   1:00PM   browns  buccaneers        23.0   \n",
       "\n",
       "   away_score              GameTime       SearchStartTime  \\\n",
       "0        28.0  2022-11-24T17:30:00Z  2022-11-20T16:30:00Z   \n",
       "1        20.0  2022-11-24T21:30:00Z  2022-11-20T20:30:00Z   \n",
       "2        26.0  2022-11-25T01:20:00Z  2022-11-21T00:20:00Z   \n",
       "3        20.0  2022-11-27T18:00:00Z  2022-11-23T17:00:00Z   \n",
       "4        17.0  2022-11-27T18:00:00Z  2022-11-23T17:00:00Z   \n",
       "\n",
       "          SearchEndTime  \n",
       "0  2022-11-24T16:30:00Z  \n",
       "1  2022-11-24T20:30:00Z  \n",
       "2  2022-11-25T00:20:00Z  \n",
       "3  2022-11-27T17:00:00Z  \n",
       "4  2022-11-27T17:00:00Z  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sched_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Week 12 Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df_wk12 = sched_df[sched_df['Week'] == 12]\n",
    "sched_df_wk12_no_thurs = sched_df_wk12.iloc[3:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagination\n",
    "\n",
    "Requests limited to 100 tweets at a time\n",
    "\n",
    "Must paginate requests using ```tweepy.Paginator```   \n",
    "```limit```: sets how many pages  \n",
    "```max_results```: sets how many results per page (limited to 100)  \n",
    "Total Results = limit * max_results  \n",
    "\n",
    "```start_time```: start of when to retrieve tweets  \n",
    "```end_time```: end of when to retrieve tweets  \n",
    "**Note**: times are in format of ```2022-11-24T15:25:00Z```  \n",
    "This is ZULU time which is **7 hours ahead of MST**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Team Paginator Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 week ago: 2022-11-23 18:53:42.984763 \t Start_time:  2022-11-23T17:55:00Z\n",
      "Start time too old\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check start time within 7 days\n",
    "\n",
    "def check_start_time_not_greater_7_days(start_time):\n",
    "    week_ago = dt.datetime.utcnow() - pd.to_timedelta('7 days')\n",
    "    print('1 week ago:', week_ago, '\\t Start_time: ', start_time)\n",
    "    check = week_ago < dt.datetime.strptime(start_time, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    if (check == False):\n",
    "        print('Start time too old')\n",
    "    else:\n",
    "        print('Start time allowed')\n",
    "    return check\n",
    "\n",
    "check_start_time_not_greater_7_days('2022-11-23T17:55:00Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_time=2019-01-01T17:00:00Z\n",
    "# end_time=2020-12-12T01:00:00Z\n",
    "#2022-11-23T20:05:00Z\t\n",
    "\n",
    "def paginate_search(team_query, max_results, start_time, end_time, limit=20):\n",
    "    start_valid = check_start_time_not_greater_7_days(start_time)\n",
    "    if (start_valid == True):\n",
    "        tweet_fields = [\"author_i``d\", \"created_at\", \"text\"]\n",
    "        paginator = tweepy.Paginator(\n",
    "            client.search_recent_tweets, \n",
    "            query = team_query, \n",
    "            tweet_fields = tweet_fields, \n",
    "            start_time=start_time, \n",
    "            end_time=end_time,\n",
    "            max_results = max_results,\n",
    "            limit = limit\n",
    "        )\n",
    "        return paginator\n",
    "    else:\n",
    "        print('Start Time Not Valid')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Paginator Search from Game Schedule\n",
    "Iterate through each game row  \n",
    "Get all data needed  \n",
    "Call paginae search for both home and away teams  \n",
    "Add to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_week_paginations_from_schedule(wk_sched_df, team_queries, max_results = 100, limit = 50):\n",
    "    paginators = {}\n",
    "    for game_row in wk_sched_df.itertuples():\n",
    "        wk = game_row.Week\n",
    "\n",
    "        start_time = game_row.SearchStartTime\n",
    "        end_time = game_row.SearchEndTime\n",
    "        \n",
    "        home_team = game_row.home\n",
    "        away_team = game_row.away\n",
    "\n",
    "        home_team_query = team_queries[str(home_team)]\n",
    "        away_team_query = team_queries[str(away_team)]\n",
    "\n",
    "        home_team_paginator = paginate_search(\n",
    "            home_team_query, \n",
    "            max_results, \n",
    "            start_time, \n",
    "            end_time,\n",
    "            limit\n",
    "        )\n",
    "        away_team_paginator = paginate_search(\n",
    "            away_team_query, \n",
    "            max_results, \n",
    "            start_time, \n",
    "            end_time,\n",
    "            limit\n",
    "        )\n",
    "        \n",
    "        home_key = 'wk_' + str(wk) + '_' + home_team\n",
    "        away_key = 'wk_' + str(wk) + '_' + away_team\n",
    "\n",
    "        paginators[home_key] = {\n",
    "            \"paginator\": home_team_paginator,\n",
    "            \"team\": home_team\n",
    "        }\n",
    "\n",
    "        paginators[away_key] = {\n",
    "            \"paginator\": away_team_paginator,\n",
    "            \"team\": away_team\n",
    "        }\n",
    "    return paginators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paginator Dictionary for Week 12 games\n",
    "Not including thursday night games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV file for team\n",
    "- Tweet Team\n",
    "- Tweet Text\n",
    "- Tweet Author\n",
    "- Tweet Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "\n",
    "def create_dataset(paginator_dict, key):\n",
    "    team = paginator_dict[str(\"team\")]\n",
    "    paginator = paginator_dict[str(\"paginator\")]\n",
    "    with open('team_data/%s_tweets.csv' % (key), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        \n",
    "        # Write header row (feature column names of your choice)\n",
    "        w.writerow(['team',\n",
    "                     'timestamp', \n",
    "                     'tweet_text', \n",
    "                     'userid' \n",
    "                     ])\n",
    "        tweet_count = 0\n",
    "        page_count = 0\n",
    "        for page in paginator: \n",
    "            page_count += 1\n",
    "            if (page.data == None):\n",
    "                print(f'NO DATA FOR {team}')\n",
    "                print(page.meta)\n",
    "            # For each tweet matching hashtag, write relevant info to the spreadsheet\n",
    "            else:\n",
    "                for tweet in page.data:\n",
    "                    tweet_count += 1\n",
    "                    w.writerow([team,\n",
    "                                tweet.created_at, \n",
    "                                tweet.text.replace('\\n',' ').encode('utf-8'), \n",
    "                                tweet.author_id, \n",
    "                                ])\n",
    "        print(f'Team: {team} \\t\\t Page Count: {page_count} \\t Tweet Count: {tweet_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_team_datasets(team_paginators):\n",
    "    # iterate through team paginator dict\n",
    "    for key, paginator_dict in team_paginators.items():\n",
    "        # pass each to create_dataset\n",
    "        # print('KEY:%s - PAGINATOR: %s ' %(key, paginator_dict))\n",
    "        create_dataset(paginator_dict, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Code to get all Datasets\n",
    "\n",
    "Had some issues with requests tapping out at certain points.  \n",
    "Had to break it up to sort it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>SearchStartTime</th>\n",
       "      <th>SearchEndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>4:05PM</td>\n",
       "      <td>cardinals</td>\n",
       "      <td>chargers</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2022-11-27T21:05:00Z</td>\n",
       "      <td>2022-11-23T20:05:00Z</td>\n",
       "      <td>2022-11-27T20:05:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Week  Day        Date    Time       home      away  home_score  \\\n",
       "11    12  Sun  2022-11-27  4:05PM  cardinals  chargers        24.0   \n",
       "\n",
       "    away_score              GameTime       SearchStartTime  \\\n",
       "11        25.0  2022-11-27T21:05:00Z  2022-11-23T20:05:00Z   \n",
       "\n",
       "           SearchEndTime  \n",
       "11  2022-11-27T20:05:00Z  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sched_df_wk12_no_thurs_2 = sched_df_wk12.iloc[7:9]\n",
    "sched_df_wk12_no_thurs_3 = sched_df_wk12.iloc[11:12]\n",
    "# sched_df_wk12_no_thurs_4 = sched_df_wk12.iloc[12:14]\n",
    "# sched_df_wk12_no_thurs_5 = sched_df_wk12.iloc[14:16]\n",
    "sched_df_wk12_no_thurs_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team: jets \t\t Page Count: 34 \t Tweet Count: 3373\n",
      "Team: bears \t\t Page Count: 24 \t Tweet Count: 2345\n"
     ]
    }
   ],
   "source": [
    "paginators_wk12 = create_week_paginations_from_schedule(sched_df_wk12_no_thurs_3, team_queries, 100)\n",
    "create_all_team_datasets(paginators_wk12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to filter out multiteam hashtags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc6efb3340bf4aae142c4471c3414bb5b17e6e80ba42a259676c40f0503db89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
